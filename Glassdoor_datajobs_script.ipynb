{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load HTML and extract data\n",
    "def extract_and_save_data(html_file_path, csv_file_path):\n",
    "    # Load the HTML content from the file\n",
    "    with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Define the patterns to search for the IDs\n",
    "    id_patterns = {\n",
    "        'job-title': re.compile(r'.*job-title.*'),\n",
    "        'job-employer': re.compile(r'.*job-employer.*'),\n",
    "        'job-location': re.compile(r'.*job-location.*'),\n",
    "        'job-salary': re.compile(r'.*job-salary.*')\n",
    "    }\n",
    "\n",
    "    # Find elements for each category and store them in a list of dictionaries\n",
    "    extracted_data = []\n",
    "    elements_lists = [soup.find_all(id=pattern) for pattern in id_patterns.values()]\n",
    "    max_elements = max(map(len, elements_lists))\n",
    "\n",
    "    # Zip the lists together, filling missing values with None\n",
    "    for elements in zip(*map(lambda lst: lst + [None] * (max_elements - len(lst)), elements_lists)):\n",
    "        job_data = {\n",
    "            'job-title': elements[0].get_text(strip=True) if elements[0] else None,\n",
    "            'job-employer': elements[1].get_text(strip=True) if elements[1] else None,\n",
    "            'job-location': elements[2].get_text(strip=True) if elements[2] else None,\n",
    "            'job-salary': elements[3].get_text(strip=True) if elements[3] else None,\n",
    "        }\n",
    "        extracted_data.append(job_data)\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    return csv_file_path\n",
    "\n",
    "# Specify the HTML file path and the desired CSV file path\n",
    "html_file_path = '/mnt/data/232 data Jobs in Glasgow, Scotland, November 2023 _ Glassdoor.html'\n",
    "csv_file_path = '/mnt/data/paired_job_data_extracted.csv'\n",
    "\n",
    "# Call the function to extract data and save it to a CSV file\n",
    "extract_and_save_data(html_file_path, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


#####################################################################################################
